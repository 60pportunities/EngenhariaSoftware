## IA Agentica
A IA agêntica tem o potencial de mudar a forma como trabalhamos e vivemos. Quando falamos de IA agêntica, convém definir exatamente o que é um agente. Trata-se de um programa desenvolvido para executar tarefas específicas de forma autônoma. Os agentes tomam decisões com base em regras predefinidas ou padrões aprendidos, interagindo com outros usuários ou o ambiente para alcançar suas metas.

Para entender seu potencial, imagine se você tivesse um assistente pessoal para seguir suas instruções o dia todo. Ele cuida dos seus impostos, monitora os números semanais de produção no trabalho, pede refeições e até reserva o filme que você quer ver com seu parceiro. A IA agêntica se baseia em várias áreas importantes que tornam essa tecnologia revolucionária. Isso porque os agentes atuam de forma independente ao tomar decisões. Eles operam automaticamente, permitindo que o sistema assuma o comando de fluxos de trabalho complexos com o mínimo de supervisão humana. Por exemplo: uma câmera de segurança com recursos de IA agêntica executa funções por conta própria, como entrar em contato com o fabricante para avisar que o armazenamento está gerando erros e precisa de uma atualização de firmware, ou chamar a polícia caso identifique um crime em andamento, tudo isso sem atenção humana. Segundo: eles são orientados por metas.

São programados para definir as próprias metas e alcançá-las. Aproveitando o exemplo da câmera, uma câmera com IA agêntica pode ser capaz de definir como meta combater crimes e, como resultado, identificar se há um crime em andamento e avisar as autoridades. Em seguida, vem o aprendizado e evolução. Como seres humanos, nós aprendemos. Os agentes de IA também aprendem e se adaptam. A IA agêntica pode aprender com as interações, se adaptar a novos dados e melhorar continuamente o desempenho. Faz isso usando aprendizado de máquina, e vamos falar mais desse assunto em um vídeo exclusivo. Por enquanto, você deve saber que a IA agêntica identifica padrões, como tendências, e aprende com esses padrões para adaptar fluxos de trabalho e aprimorar estratégias.

Por exemplo: um sistema de IA agêntica pode ver se uma mudança climática afeta as vendas de um determinado produto ou serviço, ou pode encomendar mais endurecedor para um processo de fabricação se a previsão indicar alta umidade na próxima semana. Quarto: compreensão contextual. Esses sistemas entendem o contexto com nuances. Os agentes podem tomar decisões embasadas conforme o contexto da situação, permitindo que simulem o raciocínio humano para execução. Por exemplo: um agente pode considerar fatores como clima, época do ano, mercado ou qualquer aspecto pertinente para um problema do cliente. Por fim, o que torna a IA agêntica excepcional é a utilidade em vários domínios.

Os agentes de IA encontram e usam aplicativos e dados em vários domínios e plataformas. Isso inclui atendimento ao cliente, saúde, varejo, fabricação e cibersegurança. O sistema de IA agêntica agrega valor criando soluções personalizadas e proativas que lidam com cada um desses domínios de forma diferente e mais eficaz. Essas são as cinco principais características da IA agêntica. Juntas, elas permitem que os sistemas de IA agêntica transformem seus negócios.

Quando você selecionar uma linha na transcrição, será direcionado à seção equivalente no vídeo
Para que usamos a IA agêntica? Vamos ver exemplos de diferentes setores mostrando como a IA agêntica resolve problemas de negócios.
A **Daba**, empresa de desenvolvimento de software, lançou um acelerador chamado Morpheus para promover a adoção da IA agêntica nos principais sistemas de negócios. O Morpheus utiliza equipes de agentes de IA para otimizar e automatizar processos complexos de seguros, como processamento de sinistros, integração e processamento de dados. Esse é um exemplo de desenvolvimento multiagente. Ao atribuir personas específicas a cada agente, a precisão é aprimorada, assim como o valor da eficiência para a empresa. Essa aplicação da IA agêntica permitiu que as seguradoras reduzam custos administrativos, tomem decisões mais precisas e ofereçam uma experiência mais personalizada ao cliente.

A **estrutura crewAI** para desenvolvimento da IA agêntica no setor de marketing lida com diversas tarefas especializadas, como coleta de dados, análise de acordos e geração de relatórios. A estrutura cria e gerencia agentes colaborativos de IA adaptados a necessidades específicas de marketing. Portanto, é outro sistema multiagente capaz de executar agentes com a própria persona – ou seja, responsabilidades e propósito – que trabalham juntos para solucionar problemas de negócios. Um agente pode coletar dados de clientes nas redes sociais, outro analisa sentimentos, e um terceiro gera relatórios que podem ser utilizados pela equipe de marketing. Esse sistema permite que as equipes lidem com tarefas complexas, resultando em estratégias mais embasadas. O resultado é a otimização dos esforços de marketing.

No setor de varejo, a IA agêntica aprimora as interações personalizadas com clientes. Por exemplo: se um site de varejo conhece melhor o cliente, é mais provável que disponibilize um conteúdo que lhe proporcione uma melhor experiência e ele compre mais produtos. Grupos de agentes interagem com os clientes em vários pontos de contato, como e-mail, chat e redes sociais. Esses agentes usam dados de sistemas de gestão de relacionamento com o cliente e interações anteriores para adaptar recomendações e oferecer um melhor atendimento pós-venda. Isso aumenta a fidelidade do cliente e as vendas devido à experiência de compra personalizada.

Por fim, a IA está revolucionando o setor de saúde. Nessa área, os sistemas de IA agêntica ajudam nos diagnósticos. Isso significa melhores processos para identificar problemas de saúde e recomendar os melhores tratamentos. Mais uma vez, o sistema é capaz de implantar vários agentes de IA focados em tarefas que podem incluir radiologia, análise de imagens, avaliação do histórico do paciente e recomendação de tratamento. Passei por uma cirurgia recente, e alguns desses sistemas foram usados no meu tratamento. Eles aumentaram a qualidade do atendimento que recebi, e agradeço aos agentes de IA por isso. A cada dia, existem mais estudos de caso da IA agêntica e exemplos de como essa tecnologia pode agregar valor às empresas e ser utilizada pelos usuários. Não deixe de acompanhar os estudos de caso e ver como empresas inovadoras estão resolvendo problemas de negócios com a IA agêntica.

O Centro Médico Grey Sloan é uma referência em assistência médica, mas enfrentou dificuldades consideráveis, chamando a atenção da imprensa. Alguns desafios eram altas taxas de erro de diagnóstico, longos tempos de espera para os pacientes e baixa eficiência no gerenciamento de dados de pacientes. A situação ficou tão ruim que o conselho de administração dos profissionais de saúde pediu que fossem encontradas maneiras inovadoras de melhorar a qualidade do atendimento. Na verdade, trabalhei nesse projeto. O centro fez uma parceria com minha empresa para implementar um sistema de ponta visando aprimorar o atendimento e diagnósticos e otimizar os fluxos de trabalho operacionais. Veja como a IA agêntica ajudou. O sistema que implantamos no Grey Sloan consistiu em vários agentes encarregados de funções exclusivas para otimizar diferentes aspectos da prestação de serviços de saúde.

Com a implantação de vários agentes, a empresa conseguiu adotar uma abordagem flexível em que muitos agentes trabalharam juntos para resolver os principais problemas. O que esses agentes fizeram? Os agentes de assistência ao diagnóstico utilizaram algoritmos avançados de aprendizado de máquina para analisar imagens radiológicas, exames laboratoriais e históricos de pacientes. Os agentes apresentaram aos médicos recomendações de diagnóstico em tempo real. É possível, por exemplo, identificar um bico de papagaio em um paciente pedindo a um agente que analise a radiografia e recomende possíveis tratamentos aos médicos. Esse processo foi baseado na análise minuciosa de dados e na redução de erros de diagnóstico para melhorar a precisão de avaliações médicas complexas.

Os médicos ainda tinham a palavra final, mas, considerando sua grande carga de trabalho, essa assistência tornou o diagnóstico mais eficaz. O uso de agentes para encontrar horários de consulta mais rápido e gerenciar melhor o tempo dos profissionais de saúde e dos pacientes foi importante na história de sucesso do centro. É o que chamamos de agentes de gestão de pacientes.

Eles automatizaram o agendamento das consultas dos pacientes considerando a disponibilidade dos profissionais de saúde e as necessidades dos pacientes. Quando implantamos esse agente de gestão de pacientes no sistema, vimos os resultados: uma redução expressiva no tempo de espera e agilidade nas consultas. Em média, os consultórios atenderam 30% mais pacientes, com menos cancelamentos e melhor uso do tempo dos profissionais. Além disso, esses agentes realocaram recursos e otimizaram agendamentos usando dados em tempo real, ou seja, foram tomadas decisões inteligentes usando dados quase perfeitos e atuais. Além dos agendamentos, tivemos que resolver problemas administrativos. Implantamos agentes administrativos para automatizar a entrada de dados de várias fontes, garantindo históricos de pacientes precisos e atualizados com regularidade.

Os agentes fazem o processamento de cobranças e solicitações de reembolso, diminuindo os erros e a carga de trabalho administrativa. Tenho muito orgulho de ter participado da implantação do sistema e de como ele funciona hoje. Ao liberar tempo e recursos substanciais com a IA agêntica, a equipe de saúde do centro conseguiu se concentrar mais na sua missão principal: cuidar dos pacientes.

Você pode ter um videoporteiro com campainha que identifica se uma pessoa está se aproximando da porta ou quando uma encomenda foi deixada. Já se perguntou como isso funciona? A interação com o ambiente envolve os processos de detecção e atuação, em que o agente de IA percebe seu entorno por meio de sensores, interpreta os dados, toma decisões e age para influenciar o ambiente com base nessas decisões.

Entre as fontes estão dados de imagens, áudios, vídeos ou qualquer coisa que proporcione uma compreensão abrangente do ambiente ao redor dos agentes de IA. Depois que os dados são coletados, o sistema de IA os processa e interpreta para gerar insights. Isso significa que o agente consegue interpretar esses dados, como a estrutura, relações e possíveis implicações dos dados coletados. A pessoa que está se aproximando da porta vai entregar uma encomenda ou roubar?

Em seguida, ocorre um ciclo de feedback em que os resultados das ações, como prever erroneamente que alguém vai roubar uma encomenda, são detectados e reavaliados. Com base nesse ciclo de feedback, o sistema de IA pode redefinir respostas futuras. O sistema aprende que, na verdade, a pessoa não estava roubando e deixa de fazer essas suposições no futuro.

Outro exemplo é um sistema de detecção de fraudes que funciona em celulares e utiliza a tecnologia de IA agêntica. Ao escutar uma mensagem de voz, o agente pode concluir que precisa proteger o usuário. Porém, o usuário pode dar feedback ao agente dizendo que, na verdade, é um amigo, não uma ameaça de fraude. Depois disso, o agente não vai mais sugerir que seu amigo está tentando roubar você. Ele utiliza um ciclo de feedback para se tornar mais inteligente. Os agentes também se comunicam.

Aliás, quanto mais complexo se torna um objetivo, maior a necessidade de comunicação entre agentes. Um sistema que funciona de forma independente sem se comunicar com outros agentes não tem muito valor. No caso da câmera com IA agêntica, o agente da câmera pode se comunicar com um agente de outra câmera, ou agentes de um servidor remoto, seu computador pessoal, telefone – você entendeu. Como os agentes conversam? Eles usam comunicações entre agentes. Basicamente, são todos os métodos e protocolos que os agentes usam para trocar informações. Quando isso é feito corretamente, garante que todos os agentes trabalhem de forma integrada. As informações trocadas podem incluir mensagens entre agentes, ou seja, basicamente dois agentes trocando comandos, dados ou qualquer outro elemento necessário, permitindo que executem suas tarefas. Os agentes compartilham bancos de dados ou locais onde dados persistentes são armazenados e recuperados. Pode ser qualquer marca e tipo de banco de dados. Interação direta é quando um agente faz uma conexão durável para troca de informações. É basicamente o middleware dos agentes. É claro que isso significa que os agentes foram programados para coordenar ações. A coordenação envolve as estratégias e processos que gerenciam as interações entre muitos agentes. Por exemplo, um agente monitorando o vídeo da campainha, outro agente detectando objetos que precisam ser identificados, um terceiro agente decidindo qual objeto aparece no vídeo. Você entendeu a ideia. Bem legal, não? A arquitetura da IA agêntica tem dois componentes importantes.

Primeiro, a **arquitetura que processa o**s elementos internos dos agentes e, segundo, mecanismos que permitem que os agentes conversem e coordenem ações para trabalhar juntos. Agora que você entende os conceitos fundamentais usados no desenvolvimento de todos os sistemas de IA agêntica, vamos detalhar alguns aspectos no restante do curso.

Os sistemas de IA agêntica tomam decisões complexas e alcançam metas por conta própria, sem depender de interação e intervenção humanas. Com esse benefício empolgante vem a necessidade de um planejamento cuidadoso. O esforço dedicado ao planejamento é a diferença entre um sistema de IA agêntica que agrega valor à empresa ou um fracasso total, causando até prejuízos. Se você ficou encarregado de projetar e desenvolver sistemas de IA agêntica, entenda que as estruturas de IA agêntica são a base da capacidade de planejamento e resolução de problemas da IA.

Antes, porém, vamos a uma visão geral de como esses recursos se inter-relacionam. Vamos começar pela definição das metas, o que significa apenas definir com clareza os objetivos que a IA precisa cumprir. Isso deve ser feito antes de implantar o sistema. As metas podem ser tarefas simples, como identificar alvos em movimento na frente da câmera ou navegar até um determinado local se o sistema de IA agêntica for um carro autônomo, ou processos complexos com várias etapas, como formular uma estratégia de ação com base na ocorrência de algum evento, como o veículo autônomo se envolver em um acidente e tomar medidas para lidar com possíveis ferimentos e interagir com socorristas. Identificada a meta, é preciso definir a sequência de ações que leva um agente ao estado dessa meta. Nos exemplos da câmera de segurança com IA agêntica, queremos que a câmera detecte crimes e execute ações predefinidas se um crime for observado. Portanto, o sistema de IA precisa saber como um crime é detectado e validado, como os riscos são avaliados e como as ações são realizadas, como alertar o operador ou as autoridades locais.

Pode ser assim: primeiro, observar a área. Segundo: detectar humanos. Terceiro: analisar os humanos. Quarto: identificar a intenção dos humanos. Quinto: identificar os riscos. Sexto: identificar os ganhos e perdas. Sétimo: realizar ações predefinidas. Aposto que você consegue pensar em maneiras de planejar seu sistema de IA agêntica em termos de sequências de eventos que precisam ocorrer. Agora vamos à modelagem do ambiente, que significa criar uma representação do ambiente em que a IA opera. O sistema de IA agêntica replica um ambiente físico em formato digital, para que possam ser feitas simulações visando identificar os melhores resultados. No caso de uso da câmera, a capacidade de replicar a área monitorada na câmera permite fazer simulações como modelagem de possíveis movimentações e assim por diante. É claro que o planejamento nunca tem fim.

Também precisamos conduzir um processo de planejamento contínuo, ou seja, atualizar e revisar os planos com base em novas informações e mudanças no ambiente. Por exemplo: no caso de uso da câmera de segurança, itens na área monitorada, como um banco, podem ser movidos. Assim, a câmera precisa reavaliar e replanejar com base nas mudanças ocorridas. Agora diferentes partes da imagem precisam ser tratadas de forma diferente, e é preciso refazer certas ações com base nas mudanças. Como diz o ditado, quem não planeja, planeja o fracasso. No próximo vídeo, vamos aprender mais sobre agentes autônomos: o que são, como funcionam e como são criados por pessoas como você.

O aprendizado de máquina resulta da aplicação de algoritmos para aprender com os dados e fazer escolhas sem receber instruções formais para isso. Se você achou bem parecido com a inteligência artificial, tem razão. Afinal, o aprendizado de máquina, ou machine learning, é uma forma de inteligência artificial e é a base da maioria dos sistemas de IA.

Basicamente, o ML é a teoria e a metodologia, e as estruturas de IA agêntica, que veremos nos próximos vídeos, são ferramentas práticas que dão vida à teoria. O aprendizado de máquina permite que os agentes aprendam com as experiências de modo independente, sendo utilizado há anos para resolver problemas práticos de negócios, como identificar aplicativos fraudulentos e discrepâncias contábeis. Ao treinar modelos com vastos conjuntos de dados para identificar padrões, os modelos de aprendizado de máquina proporcionaram aos agentes autonomia para tomar decisões sem supervisão humana.

É como treinar uma sala de aula cheia de gente usando essas diferentes técnicas. Existem três modelos principais de aprendizado de máquina: aprendizado supervisionado, não supervisionado e por reforço. O aprendizado supervisionado utiliza dados rotulados. O não supervisionado investiga padrões ocultos em dados não rotulados. Já o aprendizado por reforço treina os agentes recompensando-os por ações positivas. O sistema interno de aprendizado de máquina faz parte de um agente e também pode ser utilizado por um agente como recurso externo. Ele é necessário para orientar o agente na avaliação de ações, otimização de metas e execução autônoma de tarefas. Também é fundamental entender que os agentes de IA com aprendizado de máquina integrado estão em constante melhoria. Por exemplo: cada vez que são executados, descobrem algo novo para desempenhar melhor sua função.

Processam novos dados continuamente, aprimoram métricas de desempenho, melhoram a precisão das previsões e enfrentam desafios em contextos dinâmicos com mais robustez. Nós também funcionamos assim. Aprendemos com os erros e, com base no feedback do ambiente, agimos de modo diferente para melhorar a forma como nos sentimos e aproveitamos a vida.

Uma vez você saiu sem jaqueta quando estava frio, mas logo percebeu que não foi uma boa decisão e mudou seu comportamento em todos os eventos posteriores quando sabia que estava fazendo muito frio.

É basicamente disso que estamos falando, mas o que podemos fazer com tudo isso? No caso de negócios da câmera de segurança, é possível regular os recursos de resfriamento interno da câmera com base na temperatura e nível de umidade do ar e aprender continuamente o grau de ajuste necessário com base em cálculos com dados anteriores. Agora que você sabe os fundamentos teóricos e metodológicos do aprendizado de máquina, vamos conhecer melhor o mundo da IA agêntica aprendendo sobre estruturas no próximo vídeo.


Os agentes de IA podem tomar decisões de forma autônoma, mas como fazem isso de maneira coerente, previsível e ética? Uma ferramenta para conseguir isso é uma estrutura de políticas. Como você já deve saber, uma estrutura, ou framework, é um modelo geral que desenvolvedores como você podem usar para criar aplicativos, definindo como diferentes partes dos sistemas interagem e se integram. Mas o que são estruturas de políticas? São diretrizes que controlam e orientam ações, conciliando-as com as normas e valores definidos por arquitetos, projetistas, desenvolvedores ou usuários finais.

**Elabore uma estrutura de políticas para organizar como o sistema de IA agêntica toma decisões e segue regras para garantir que atenda às expectativas. Se essas políticas não forem definidas, o sistema pode executar ações indesejadas, como enviar informações pessoais para um sistema solicitante sem perguntar a você ou até realizar tarefas ilegais ou antiéticas.**

Vamos examinar duas estruturas de políticas: as de tomada de decisões e as baseadas em regras. As estruturas de tomada de decisões incluem políticas éticas para assegurar que as ações da IA atendam aos padrões sociais e legais em geral, garantindo que o sistema de IA agêntica não infrinja a legislação nem cause transtornos aos usuários por meio de comportamentos destrutivos. As estruturas de tomada de decisão também incluem mecanismos de supervisão.

Trata-se da implementação de sistemas human-in-the-loop ou human-on-the-loop para garantir que os operadores humanos possam intervir na tomada de decisões da IA, conforme necessário.

- [ ] **Human-In-The-Loop (HITL)** é um mecanismo que combina a inteligência humana com a automação para treinar, afinar, ou testar certos sistemas, como modelos de IA, para alcançar os resultados mais precisos e confiáveis.
![[Pasted image 20250601174932.png]]

- [ ]


Um exemplo é um botão de emergência integrado no sistema que permita a um operador humano interromper as operações, se necessário. Também existem estratégias de avaliação e redução de riscos, que abordam possíveis resultados adversos de decisões autônomas tomadas por agentes de IA. No nosso exemplo da câmera de segurança, a polícia é acionada se houver suspeita de um crime ocorrendo, mas garantimos que isso não ocorra com base em preconceitos como raça e idade. O segundo tipo de estrutura de políticas é a baseada em regras. São regras predefinidas que os sistemas de IA agêntica precisam seguir para garantir um comportamento previsível e em conformidade.

Como exemplo, uma regra que a IA precisa seguir pode ser nunca tentar ferir um humano. Nas estruturas baseadas em regras, embora a adaptabilidade permita que a IA modifique seus comportamentos em resposta a mudanças nas condições, ela ainda precisa seguir regras e objetivos. Pode, por exemplo, alterar o comportamento com base em mudanças das condições climáticas, modificando a combinação de materiais em um processo de fabricação sensível à temperatura. Porém, não basta definir as estruturas de políticas e tomada de decisão e nunca revisar esse trabalho. Também é fundamental estabelecer sistemas de monitoramento contínuo das ações da IA para assegurar a conformidade com as regras definidas.

Vamos continuar falando das estruturas de IA agêntica analisando estruturas baseadas na utilidade. Lembre-se: as estruturas garantem que os agentes de IA operem com autonomia para alcançar metas. As estruturas baseadas na utilidade para IA agêntica são modelos conceituais que orientam o projeto, a implantação e a avaliação dos sistemas de IA. Elas visam maximizar sua utilidade, equilibrando os riscos e benefícios. Quais são os componentes fundamentais das estruturas baseadas na utilidade? Vamos abordar os componentes mais importantes, começando pelas funções de utilidade.

A função de utilidade associa os resultados a valores numéricos, calculando se são desejáveis. O sistema de IA usa essa função para avaliar e escolher as melhores ações com base nos cálculos. Suponha que uma câmera de segurança registre uma imagem de uma pessoa carregando um objeto. Esse objeto pode ser uma arma ou uma ferramenta não ameaçadora, e a câmera deve avaliar a imagem para identificar isso. Nessa situação, a função de utilidade atribui uma classificação à imagem, podendo ser de 1 a 10, por exemplo, onde 1 é menos provável de ser uma arma e 10 é mais provável.

Essa fórmula é então usada para prever se a pessoa é uma ameaça que precisa ser monitorada com mais atenção. Outra característica importante das estruturas baseadas na utilidade é a modelagem de preferências. Isso significa definir as preferências do usuário e integrá-las à função de utilidade, assim como as preferências que podemos configurar no celular ou até na TV. Isso maximiza a utilidade no sistema de IA agêntica, permitindo que sempre encontre a solução ideal. Por exemplo: a imagem da câmera de segurança com IA agêntica precisa ser otimizada para análise antes que o agente tome a decisão. Isso não quer dizer que não haja riscos envolvidos.

Assim como as decisões que tomamos no dia a dia, cada decisão que um agente de IA toma envolve um determinado grau de risco e incerteza. Essas estruturas de utilidade geralmente utilizam modelos e técnicas probabilísticas para identificar, analisar, gerenciar e reduzir riscos. Você pode pensar em alguns usos disso, como identificar os riscos associados aos vieses intrínsecos de um sistema de IA agêntica. Isso leva em consideração os riscos das partes interessadas. Em seguida, é feita a análise de ganhos e perdas, que, junto com a análise de riscos, maximiza a utilidade. A análise de ganhos e perdas envolve equilibrar objetivos e restrições conflitantes, assim como fazemos todos os dias na vida. Por exemplo: se o tempo parece nublado, avaliamos os prós e contras de levar um guarda-chuva e a chance de chover. Se não chover, o guarda-chuva será apenas um estorvo.

Os sistemas de IA agêntica devem ser projetados para lidar com esses ganhos e perdas, analisando os prós e contras dos diferentes resultados e otimizando-os para chegar a uma solução equilibrada e condizente com as metas e objetivos gerais definidos no sistema de IA agêntica.

Os algoritmos de aprendizado por reforço são fundamentais no desenvolvimento do aprendizado de máquina e da IA agêntica. Esses algoritmos se aplicam a várias situações práticas, como direção autônoma, em que os agentes aprendem a navegar por estradas, ou solução de problemas em um motor a jato durante o voo, buscando automaticamente o resultado mais seguro e eficaz.

O aprendizado por reforço se resume a aprender interagindo com um ambiente. O agente atua em diferentes situações, também chamadas de estados, e recebe feedback na forma de recompensas ou punições. Os agentes tentam maximizar as recompensas, assim como as pessoas quando recebem recompensas por bom comportamento ou boas notas na escola. O agente entende que não é desejável receber uma penalidade e tenta descobrir como evitá-la no futuro. O Q-learning é um tipo específico de algoritmo de aprendizado por reforço. Ele usa uma tabela Q para monitorar as melhores ações a tomar em cada situação.

O agente atualiza essa tabela com base nas experiências, aprendendo gradualmente as ações ideais para maximizar as recompensas. Como desenvolver um algoritmo de Q-learning? O primeiro passo é definir o ambiente. Trata-se do mundo em que o agente interage. O ambiente inclui todos os estados, ações e regras de interação possíveis. Abrange tudo o que o agente pode fazer e as respostas que os agentes vão receber, inclusive políticas e regras aplicáveis. Segundo: identifique os diferentes estados possíveis do sistema. Um estado é uma representação da situação ou configuração do ambiente em um determinado momento. Por exemplo: o fato de estar escuro lá fora é um exemplo de um estado que o agente da câmera deve entender. Terceiro: defina o conjunto de ações que o agente pode tomar. Por exemplo: a câmera pode alterar a abertura em resposta ao estado de escuridão, ou um agente encarregado de monitorar um motor a jato pode acionar um sistema de combate a incêndio caso detecte um foco de incêndio. Quarto: estabeleça um sinal de recompensa. Como é que é? Pense nisso como uma versão digital dos petiscos para cachorros.

Recompensas são valores numéricos que o agente recebe após realizar uma ação em um determinado estado. A meta do agente é maximizar os prêmios acumulados. Quinto: elabore políticas. Por exemplo: uma política da companhia aérea é nunca desligar o motor a jato durante o voo. Você precisa de uma estratégia ou de um mapeamento entre estados e ações para orientar o agente. Por fim, defina uma função de valor. Essa função estima a recompensa acumulada esperada por permanecer em um determinado estado e seguir certa política. A função de valor ajuda o agente a avaliar o benefício de estados e ações no longo prazo, assim como identificamos os benefícios de longo prazo das nossas ações, tanto boas quanto ruins. Com o aprendizado por reforço, os agentes de IA estão em um constante estado de autodescoberta. Eles estão sempre melhorando o desempenho, tornando-se capazes de enfrentar desafios cada vez maiores. São muitos detalhes, mas lembre-se: não se trata de memorizar. Isso não vai ajudar muito. Compreender como os agentes de IA realizam tarefas conceitualmente é útil, porque você pode entender como isso se encaixa no mundo da IA agêntica como um todo. Lembre-se do que é aprendizado por reforço e de que ele pode ser utilizado quando necessário.

Pense em luto perinatal, que poderia diminuir o trauma. Agora o mundo não para.. Olhe para os robôs e ia da CANTON FAIR 2025. Mas efetivamente insights para melhoria do ser.

https://dev.to/feministech/o-que-e-devrel-40fd

Enquanto houver uma discussão como esta o Brasil só perdemos… Excesso de roubo, falácias em Direitos Humanos e Igualdade Racial, Mais um plano de moradia favorecendo as grandes empresas, bancos e vamos nessa.
Os dois Lula e Bolsonaro não deveriam voltar para a Política. Precisamos de um grupo NOVO, que entenda as mudanças do MUNDO.

Enquanto cantávamos  Os Incríveis com  "Prá frente Brasil", viamos Pelé, países que comunistas, viraram capitalistas, países destruídos viraram potencia comercial.. E nós?

Vietnã – Início da industrialização pós-1975.
China - 1978


[

## Os Incríveis

](https://www.letras.mus.br/os-incriveis/)


Imagine se a imprensa descobrisse que um sistema de aprovação de empréstimos de um banco importante estava recusando pedidos de empréstimo de pessoas de uma determinada raça.

Seria ilegal, constrangedor para o banco e imoral.

A ética precisa ser levada em conta no projeto, desenvolvimento, implantação e operações dos sistemas de IA agêntica.

Isso exige que a empresa defina sua **visão de imparcialidade, viés, transparência, responsabilidade, privacidade e proteção de dados. Com esse trabalho concluído, podem ser projetadas estruturas éticas de IA agêntica**.

Como garantir a imparcialidade usando estruturas? Estruturas de imparcialidade ajudam os desenvolvedores a projetar sistemas que minimizam vieses nos sistemas de IA. Elas orientam os agentes na identificação e redução dos vieses garantindo que os conjuntos de dados representem perspectivas diversas e inclusivas. Treinamos os agentes para eliminar vieses.

Quando isso é feito corretamente, todos os usuários são tratados com equidade, independentemente da raça, gênero ou idade. Porém, uma ideia comum na ética é que um sistema não pode realmente tratar os outros com imparcialidade sem considerar a transparência e a explicabilidade. A transparência e a explicabilidade visam tornar o funcionamento interno dos sistemas de IA compreensível para todos os interessados. Transparência envolve o compartilhamento aberto dos processos, dados e lógica por trás das decisões de um sistema. Explicabilidade diz respeito à capacidade de apresentar explicações claras sobre as decisões da IA e documentar os processos de projeto e tomada de decisão. A inclusão desses princípios no projeto está de acordo o processo desejado pela maioria dos interessados: confie, mas verifique. Eles não querem publicidade negativa nem a sensação desagradável de prejudicar pessoas por causa de problemas no sistema de IA agêntica. Isso promove confiança e responsabilidade. Além disso, permite que haja uma pista de auditoria. Todas as ações são documentadas. Agora vamos falar um pouco mais de responsabilidade.

É preciso projetar e desenvolver sistemas com automonitoramento, para que os problemas sejam identificados e eliminados. Isso envolve estabelecer políticas e procedimentos de governança e definir as responsabilidades por eventuais danos ou erros causados por sistemas de IA. Os desenvolvedores precisam atuar conforme a legislação e as normas éticas. Há muito em jogo, incluindo multas pesadas e danos à reputação se os problemas não forem descobertos. Sem pressão. Não se esqueça do direito à privacidade e proteção de dados. Você gostaria que um agente de IA transmitisse informações pessoais suas para uma entidade externa? Isso não é bom. Para ajudar na proteção de dados, o desenvolvimento da IA deve enfatizar a minimização e a anonimização dos dados. Minimização significa coletar apenas dados necessários, e anonimização significa eliminar tudo que permita que os dados sejam associados a alguém. Um exemplo é se um agente revelar seu histórico médico, incluindo informações pessoais. Ao se concentrar nesses conceitos centrais, é possível projetar e implementar sistemas de IA agêntica de forma ética. Isso não é uma opção. É uma necessidade. A ética sempre deve fazer parte da conversa ao usar a IA.
x
O GitHub Copilot representa uma mudança monumental na forma como o código é escrito, oferecendo a você um parceiro excepcional em sua jornada de codificação.
O GitHub Copilot não é apenas uma ferramenta; ele está transformando o conceito de programação em pares.



O GitHub Copilot é um assistente de programação baseado em IA desenvolvido pelo GitHub em parceria com a OpenAI.

A engenharia de prompts é a prática de estruturar comandos ou instruções para obter os melhores resultados possíveis de modelos de IA generativa.
A qualidade das sugestões geradas pelo GitHub Copilot depende diretamente da clareza dos prompts fornecidos.
Prompts bem elaborados ajudam a IA a entender melhor o contexto do problema, resultando em saídas mais úteis e precisas.

| Ideia da IA                | Entenda                                                               |
| -------------------------- | --------------------------------------------------------------------- |
| Imparcialidade             | Os sistemas de IA devem tratar todas as pessoas de maneira imparcial. |
| Confiabilidade e segurança | O desempenho dos sistemas de IA deve ser confiável e seguro.          |
| Privacidade e segurança    | Os sistemas de IA devem ser seguros e respeitar a privacidade.        |
| Inclusão                   | Os sistemas de IA devem capacitar a todos e engajar as pessoas.       |
| Transparência              | Os sistemas de IA devem ser compreensíveis.                           |
| Responsabilidade           | As pessoas devem ser responsáveis pelos sistemas de IA.               |

| Modelo/Produto                       | Fornecedor         | Finalidade Principal                                                              | Público-Alvo                         | Principais Recursos                                                                | Integração                                 | Casos de Uso Comuns                                                          |
| ------------------------------------ | ------------------ | --------------------------------------------------------------------------------- | ------------------------------------ | ---------------------------------------------------------------------------------- | ------------------------------------------ | ---------------------------------------------------------------------------- |
| **Serviços de IA do Azure**          | Microsoft          | Oferecer APIs e serviços de IA prontos para uso (visão, linguagem, voz, decisão)  | Desenvolvedores, empresas            | APIs pré-treinadas, personalização, escalabilidade                                 | Azure, REST APIs, SDKs                     | Chatbots, análise de imagens, tradução automática, reconhecimento de fala    |
| **Portal da Fábrica de IA do Azure** | Microsoft          | Interface para criar, implantar e gerenciar soluções de IA                        | Engenheiros de IA, cientistas        | Modelos pré-construídos, pipelines de dados, monitoramento                         | Azure Machine Learning, Power BI           | Desenvolvimento de modelos personalizados, automação de fluxos de trabalho   |
| **AI Builder**                       | Microsoft          | Criar modelos de IA sem código para automação de processos                        | Usuários de negócios, Power Platform | Modelos pré-treinados (formulários, previsões), integração com Power Apps/Automate | Power Apps, Power Automate, Dynamics 365   | Extração de dados de documentos, automação de tarefas repetitivas            |
| **Copilot Studio**                   | Microsoft          | Criar e personalizar copilots (assistentes de IA) para interações conversacionais | Desenvolvedores, equipes de TI       | Interface low-code, conectores a dados externos, GPT-4 integrado                   | Microsoft 365, Teams, Power Platform       | Chatbots empresariais, suporte ao cliente automatizado                       |
| **SDK do Semantic Kernel**           | Microsoft          | Integrar modelos de IA (como LLMs) em aplicativos com orquestração de tarefas     | Desenvolvedores avançados            | Composição de habilidades, plugins, planejamento de tarefas                        | Azure OpenAI, ChatGPT, APIs personalizadas | Aplicativos com raciocínio contextual, automação complexa                    |
| **Visual Studio IntelliCode**        | Microsoft          | Auxiliar na escrita de código com sugestões baseadas em IA                        | Desenvolvedores                      | Autocompletar contextual, recomendações de padrões                                 | Visual Studio, VS Code                     | Aceleração de desenvolvimento, redução de erros                              |
| **ChatGPT**                          | OpenAI             | Gerar texto, responder perguntas e realizar tarefas de linguagem natural          | Público geral, desenvolvedores       | Conversação natural, suporte a múltiplos idiomas, customização via prompts         | API OpenAI, aplicativos personalizados     | Suporte virtual, criação de conteúdo, tutoriais interativos                  |
| **GitHub Copilot**                   | Microsoft (GitHub) | Sugerir código em tempo real com base em contexto                                 | Desenvolvedores                      | Autocompletar código, suporte a múltiplas linguagens, integração com editores      | VS Code, Visual Studio, JetBrains          | Aceleração de codificação, redução de bugs, aprendizado de novas tecnologias |

Com base no  GPT-3, em 2021, o GitHub e a OpenAI trabalharam em conjunto em um modelo foi chamado OpenAI Codex. O modelo Codex foi treinado em bilhões de  linhas de código de fontes disponíveis publicamente, bem como de repositórios públicos do GitHub.



- [ ] https://learn.microsoft.com/pt-br/training/modules/get-started-github-copilot/?wt.mc_id=1reg_24497_webpage_reactor

- [ ] https://www.builder.io/blog/cursor-vs-github-copilot

- [ ] https://learn.microsoft.com/pt-br/training/modules/github-copilot-across-environments/?wt.mc_id=1reg_24497_webpage_reactor

- [ ] https://developer.microsoft.com/pt-br/reactor/series/S-1447/?wt.mc_id=seriespg_S-1447_webpage_reactor

- [ ] https://learn.microsoft.com/pt-br/training/paths/copilot/?wt.mc_id=github_inproduct_copilotfoundations_mslearn_ghcertregistration

O desenvolvimento de software produz um número tão grande de ferramentas e tecnologias para tornar o trabalho eficiente, a ponto de induzir fadiga de decisão.
o que significa ser produtivo?
